
## Logit function
_Logarithm of odds function, gives probability distribution_

* Is the inverse of the [[Week 1 - Linear Classifiers NLP#Sigmoid|sigmoid function]]
* ![[Pasted image 20240205104402 1.png|500]]


## ReLU

* Popular in convolutional neural networks
* may cause inactive nodes, as negative gradients are set to 0
* alternatives with non-zero gradient: 
	* leaky ReLU: $g(x) = max(0.01x,x)$
	* Gaussian Error Linear Units (GELUs)
	* ELU


# Neural networks
---

* Two types:
![[Pasted image 20240205113632 1.png|600]]

# Notation

![[Pasted image 20240205114253 1.png|600]]

