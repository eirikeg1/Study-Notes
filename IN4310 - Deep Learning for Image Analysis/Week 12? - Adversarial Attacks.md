#toExpand 


* Why is it effective?
* Understanding of the taxonomy of defense and how they work
* 

# Black box attack
_Only access to output of the model_

## Surrogate attacks
_

## Boundary attacks


# White box attacks

## Iterative Gradient Methods


## Projected Gradient Methods
_constrain the norm of perturbations

### Selecting Ln Norm

* $L_{1}\text{-Norm}$ encourages to update in one direction (moves in jagged lines)
* ![[Pasted image 20240415104427.png|350]]



# Well-posedness
_Term which describes problems which are solvable
* Solution exists
* Solution i unique
* Solution changes continuously with input


# Ill-conditioning
_Small changes in inputs can lead to very large changes in outputs_
* Even if continuous mappings are technically stable, they can exhibit bad behavior
* ![[Pasted image 20240415112106.png|350]]

## Relative condition number
_Tells us how sensitive a function is to a perturbation at a point x_

* Lipschits #toExpand
* ![[Pasted image 20240415112322.png|350]]


## Matrix conditioning

![[Pasted image 20240415112805.png|400]]





# Adversarial training
#toExpand
* Model is harder to fool, but generally much worse


